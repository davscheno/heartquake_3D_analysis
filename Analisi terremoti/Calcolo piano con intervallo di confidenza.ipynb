{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gmplot\n",
    "#!pip install pyproj\n",
    "#!pip install mplstereonet\n",
    "#!pip install shapely\n",
    "#!pip install geopandas\n",
    "#!pip install uncertainties\n",
    "#!pip install plotly==4.3.0\n",
    "#!pip install \"notebook>=5.3\" \"ipywidgets>=7.2\"\n",
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": [
     "piano"
    ]
   },
   "outputs": [],
   "source": [
    "def piano(A,B,C_,D):\n",
    "\n",
    "    #calcolo E\n",
    "    E=np.sqrt(A**2 + B**2 + 1)\n",
    "\n",
    "    #calcolo i coseni\n",
    "    cos_a = A/E\n",
    "\n",
    "    cos_b = B/E\n",
    "\n",
    "    cos_cp = C_/E  #gamma_p\n",
    "\n",
    "\n",
    "    cos_c = np.cos((np.pi/2) + np.arccos(C_/E))   #controllare se è corretto \n",
    "\n",
    "    #calcolo la direzione teta del vettore, il coseni direttori danno la direzione del vettore occorrre aggiungere 90°\n",
    "    teta_primo = np.arctan(cos_a/cos_b)   #espresso in radianti\n",
    "    teta_deg = (teta_primo*180)/np.pi \n",
    "\n",
    "    #calcolo della direzione della massima pendenza sul piano\n",
    "    #dip_direction = teta_deg \n",
    "\n",
    "    #calcolo l'immersione dip angolo tra la verticale e il piano\n",
    "    dip_vert = np.arcsin(-1*cos_c)\n",
    "    dip_deg = (dip_vert*180)/np.pi\n",
    "\n",
    "    #calcolo l'immersione dip\n",
    "    dip = dip_deg\n",
    "    #occorre orientare correttamente il dip_direction\n",
    "    #cond_1 = dip_direction = teta_deg\n",
    "    #cond_2 = dip_direction = teta_deg + 180\n",
    "    #cond_3 = dip_direction =  teta_deg + 360\n",
    "\n",
    "    #def orientation(cos_a,cos_b):\n",
    "\n",
    "    if cos_a > 0 and cos_b > 0:                \n",
    "        dip_direction = teta_deg\n",
    "        if cos_cp <0:\n",
    "            dip_direction =  dip_direction + 180\n",
    "\n",
    "    if  cos_a > 0 and cos_b < 0:\n",
    "        dip_direction = teta_deg + 180\n",
    "        if cos_cp <0:\n",
    "            dip_direction =  dip_direction + 180\n",
    "\n",
    "\n",
    "    if  cos_a < 0 and cos_b < 0:\n",
    "        dip_direction = teta_deg + 180\n",
    "        if cos_cp <0:\n",
    "            dip_direction =  dip_direction - 180\n",
    "\n",
    "\n",
    "    if  cos_a < 0 and cos_b > 0:\n",
    "        dip_direction =  teta_deg + 360\n",
    "        if cos_cp <0:\n",
    "            dip_direction =  dip_direction - 180\n",
    "\n",
    "    #creo l'array per il plotaggio su stereogramma\n",
    "    plot_dip_direction = 0\n",
    "    plot_dip = 0\n",
    "    plot_dip_direction = np.append(plot_dip_direction, dip_direction)\n",
    "    plot_dip = np.append(plot_dip, dip)\n",
    "    print(\"dip_direction= %f ; dip= %f\" % (dip_direction, dip))\n",
    "    print(cos_a, cos_b)\n",
    "    print('##################################################')\n",
    "    print(teta_deg)\n",
    "    output = \"teta= %f ; dip= %f\" % (dip_direction, dip)\n",
    "    file = open(\"giacitura_cluster_xx_plane.txt\",\"w\")\n",
    "    file.write(output)\n",
    "    file.close()\n",
    "\n",
    "    daframe_cluster_xx = pd.DataFrame.to_csv(df_cluster_2)\n",
    "    file = open(\"daframe_cluster_xx_plane.csv\",\"w\")\n",
    "    file.write(daframe_cluster_xx)\n",
    "    file.close()\n",
    "\n",
    "    #salva i risultati su di un file shape\n",
    "    geometry = [Point(xy) for xy in zip(df_cluster_2.x , df_cluster_2.y)]\n",
    "    df_shape = df_cluster_2.drop(['x', 'y','Ora', 'Data', 'Sec'], axis=1)\n",
    "    crs = {'init': 'epsg:3003'}\n",
    "    gdf = GeoDataFrame( df_shape, crs=crs, geometry=geometry)   #df_shape,\n",
    "    gdf.to_file(driver = 'ESRI Shapefile', filename= \"result_xx_plane.shp\" )\n",
    "\n",
    "\n",
    "\n",
    "    strike = plot_dip_direction - 90 \n",
    "    dip =  plot_dip\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='stereonet')\n",
    "    ax.plane(strike, dip)\n",
    "    ax.pole(strike, dip ,markersize=5)\n",
    "    ax.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": [
     "mappa"
    ]
   },
   "outputs": [],
   "source": [
    "def map_google():\n",
    "    #Creo una mappa dei punti su google maps\n",
    "\n",
    "    from gmplot import gmplot\n",
    "    gmap = gmplot.GoogleMapPlotter( 44.5514, 9.4335, 13)\n",
    "\n",
    "    # Scatter points\n",
    "    top_attraction_lats = df['Latitud.']\n",
    "    top_attraction_lons = df['Longit.']\n",
    "\n",
    "\n",
    "    filter_attraction_lats = df_filter['Latitud.']\n",
    "    filter_attraction_lons = df_filter['Longit.']\n",
    "\n",
    "    cluster_attraction_lats = df_cluster_2['Latitud.']# *******ATTENZIONE SONO DATI FILTRATI E CLUSTERIZZATI\n",
    "    cluster_attraction_lons = df_cluster_2['Longit.']\n",
    "\n",
    "\n",
    "\n",
    "    gmap.scatter(top_attraction_lats, top_attraction_lons, '#3B0B39', size=100, marker=False)\n",
    "\n",
    "    #gmap.scatter(filter_attraction_lats, filter_attraction_lons, '#f90707', size=40, marker=False)\n",
    "\n",
    "    gmap.scatter(cluster_attraction_lats, cluster_attraction_lons, '#1307f9', size=50, marker=False)\n",
    "\n",
    "    gmap.heatmap(cluster_attraction_lats, cluster_attraction_lons ) # crea una heatmap\n",
    "    # Draw\n",
    "    gmap.draw(\"my_map_time.html\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": [
     "3d_plane"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_3d_plane(Z, z_err1, z_err2):\n",
    "    \n",
    "    \n",
    "\n",
    "    trace1 = go.Scatter3d(\n",
    "    x=data_orig[:,0],\n",
    "    y=data_orig[:,1],\n",
    "    z=data_orig[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=4, color='red', line=dict(color='black', width=0.5), opacity=0.85)\n",
    ")\n",
    "\n",
    "\n",
    "    trace2 = go.Surface(z=Z, x=X, y=Y, colorscale='RdBu', opacity=0.6)\n",
    "    trace3 = go.Surface(z=z_err_1, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace4 = go.Surface(z=z_err_2, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    #best_fit_plane = trace3\n",
    "    # Package the trace dictionary into a data object\n",
    "    data_test1 = go.Data([ trace1, trace2,trace3,trace4])\n",
    "\n",
    "    # Dictionary of style options for all axes\n",
    "    axis = dict(\n",
    "        showbackground=True, # show axis background\n",
    "        backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "        gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "        zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    "    )\n",
    "\n",
    "    # Make a layout object\n",
    "    layout = go.Layout(\n",
    "        title='plane _error', # set plot title\n",
    "        scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "            xaxis=go.XAxis(axis), # set x-axis style\n",
    "            yaxis=go.YAxis(axis), # set y-axis style\n",
    "            zaxis=go.ZAxis(axis)),  # set z-axis style\n",
    "    )\n",
    "\n",
    "    # Make a figure object\n",
    "    fig = go.Figure(data=data_test1, layout=layout)\n",
    "\n",
    "    # Send to Plotly and show in notebook\n",
    "    #py.iplot(fig, filename='test1') # decommentare per plottare su server online\n",
    "    plot(fig)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_9_plane(Z,Z_0,Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7):\n",
    "    \n",
    "    \n",
    "\n",
    "    trace1 = go.Scatter3d(\n",
    "    x=data_orig[:,0],\n",
    "    y=data_orig[:,1],\n",
    "    z=data_orig[:,2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=4, color='red', line=dict(color='black', width=0.5), opacity=0.85)\n",
    ")\n",
    "\n",
    "\n",
    "    trace2 = go.Surface(z=Z, x=X, y=Y, colorscale='RdBu', opacity=0.6)\n",
    "    trace3 = go.Surface(z=Z_0, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace4 = go.Surface(z=Z_1, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace5 = go.Surface(z=Z_2, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace6 = go.Surface(z=Z_3, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace7 = go.Surface(z=Z_4, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace8 = go.Surface(z=Z_5, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace9 = go.Surface(z=Z_6, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    trace10 = go.Surface(z=Z_7, x=X, y=Y, colorscale='Viridis', opacity=0.6,showscale=False,)\n",
    "    #best_fit_plane = trace3\n",
    "    # Package the trace dictionary into a data object\n",
    "    data_test1 = go.Data([ trace1, trace2,trace3,trace4,trace5, trace6,trace7,trace8,trace9, trace10])\n",
    "\n",
    "    # Dictionary of style options for all axes\n",
    "    axis = dict(\n",
    "        showbackground=True, # show axis background\n",
    "        backgroundcolor=\"rgb(204, 204, 204)\", # set background color to grey\n",
    "        gridcolor=\"rgb(255, 255, 255)\",       # set grid line color\n",
    "        zerolinecolor=\"rgb(255, 255, 255)\",   # set zero grid line color\n",
    "    )\n",
    "\n",
    "    # Make a layout object\n",
    "    layout = go.Layout(\n",
    "        title='plane _error', # set plot title\n",
    "        scene=go.Scene(  # axes are part of a 'scene' in 3d plots\n",
    "            xaxis=go.XAxis(axis), # set x-axis style\n",
    "            yaxis=go.YAxis(axis), # set y-axis style\n",
    "            zaxis=go.ZAxis(axis)),  # set z-axis style\n",
    "    )\n",
    "\n",
    "    # Make a figure object\n",
    "    fig = go.Figure(data=data_test1, layout=layout)\n",
    "\n",
    "    # Send to Plotly and show in notebook\n",
    "    #py.iplot(fig, filename='test1') # decommentare per plottare su server online\n",
    "    plot(fig)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": [
     "import"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANTE ATTENZIONE OCCORRE CONVERTIRE IL FILE DIINGRESSO DEI PUNTI\n",
    "# IN COORDINATE PIANE METRICHE \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "\n",
    "##################################error\n",
    "from uncertainties import ufloat\n",
    "from uncertainties.umath import *  # sin(), etc.\n",
    "import uncertainties.umath as umath\n",
    "import uncertainties.unumpy  as unumpy\n",
    "import math\n",
    "\n",
    "\n",
    "import mplstereonet\n",
    "#from mpl_toolkits.basemap import pyproj\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from pyproj import Proj, transform\n",
    "###################################plotly_block###################################################### \n",
    "# Import plotly package online####################\n",
    "import plotly\n",
    "#plotly.tools.set_credentials_file(username='davide.schenone', api_key='WBSgVI0FXgSIRecK2cHU')\n",
    "import plotly.graph_objs as go\n",
    "# Check ploltly version\n",
    "plotly.__version__\n",
    "\n",
    "#plotly offline###############\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import *\n",
    "init_notebook_mode(connected=True) #attivando o disattivando questa riga si ottiene un plot \n",
    "                                   #contestuale rispettivamente in notebook oppure su un html\n",
    "import statsmodels.api as sm  #https://www.statsmodels.org/stable/regression.html\n",
    "    \n",
    "# To communicate with Plotly's server, sign in with credentials file\n",
    "#import plotly.plotly as py\n",
    "################################################################################################\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "# Create data with x and y random over [-2, 2], and z a Gaussian function of x and y.\n",
    "#np.random.seed(12345)\n",
    "#x = 2 * (np.random.random(500) - 0.5)\n",
    "#y = 2 * (np.random.random(500) - 0.5)\n",
    "\n",
    "#def f(x, y):\n",
    " #   return np.exp(-(x + y ** 2))\n",
    "\n",
    "#z = f(x, y)\n",
    "\n",
    "#imposto i dati\n",
    "#importa il file originale\n",
    "#df = pd.read_csv('Saorge_Taggia_erh_erz_prof.csv', sep='\\t', names=['y', 'x','z','a','b'])\n",
    "\n",
    "#importa il file convertito con convergo\n",
    "df = pd.read_excel('terremoti_santo.xlsx', sheet_name='Foglio1')\n",
    "\n",
    "\n",
    "df['z'] = df['Prof corr']  #creo il campo z profondità con valori negativi\n",
    "\n",
    "\n",
    "df['Data'] = df['Data'].astype(str).str.zfill(6) #riempie la mancanza dello zero nei primi valori\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%y%m%d')\n",
    "df['Data_subtr']=pd.to_datetime('890101', format='%y%m%d')\n",
    "df['Deltatime'] = df['Data'] - df['Data_subtr']\n",
    "df['Deltatime'] = df['Deltatime'].dt.days\n",
    "#con questo posso fare dei cluster temporali\n",
    "\n",
    "#converto le coordinate wgs 84 in UTM epsg 3003 Gauss-Boaga \n",
    "x1 = np.array(df['Longit.'])\n",
    "y1 = np.array(df['Latitud.'])\n",
    "\n",
    "\n",
    "inProj = Proj('epsg:4326')\n",
    "outProj = Proj('epsg:3003')\n",
    "x2,y2 = transform(inProj,outProj, x1, y1)\n",
    "\n",
    "df['x'] = x2\n",
    "df['y'] = y2\n",
    "\n",
    "#con questo posso fare dei cluster temporali\n",
    "#IMPOSTO I FILTRI\n",
    "\n",
    "#df_filter = df.query('Erh<1 and Erz<4') #imposto i parametri di filtro sugli errori orizzontali e verticali\n",
    "\n",
    "\n",
    "#df_filter = df.query('<Deltatime<') #imposto il filtro sulla data\n",
    "\n",
    "#imposto i pesi per il calcolo del piano da utilizzare in caso di regressione lineare pesata\n",
    "\n",
    "df['weight_calc'] = df['Nf']/24 - 0.25\n",
    "def weight(df):\n",
    "    if df['Nf'] <=6 :\n",
    "        return 0\n",
    "    \n",
    "    elif  df['Nf'] > 6 and df['Nf']  < 30   :\n",
    "        return df['weight_calc']\n",
    "            \n",
    "    elif  df['Nf'] >= 30 :\n",
    "        return 1\n",
    "\n",
    "df['weights'] =  df.apply(weight, axis=1) \n",
    " \n",
    "\n",
    "    \n",
    "df_filter = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 62, -1: 61, 3: 42, 2: 25, 1: 19})\n",
      "Counter({0: 46, -1: 10, 1: 6})\n"
     ]
    }
   ],
   "source": [
    "coords =np.vstack(df_filter[\"Deltatime\"])\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "#standard eps=70 min_samples = 10\n",
    "db = DBSCAN(eps=70, min_samples=10).fit(coords)\n",
    "labels = db.labels_\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "df_filter = df_filter.assign(Classe = labels)\n",
    "print(Counter(labels))\n",
    "#filtro la label di interesse\n",
    "df_cluster = df_filter[df_filter['Classe'] == 0] # <=========================\n",
    "\n",
    "#################################################\n",
    "df_filter_2 = df_cluster\n",
    "coords_2 = df_filter_2[['x', 'y','z']].to_numpy() #previus as_matrix\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "#base eps 3000 min_samples 5\n",
    "db = DBSCAN(eps=3000, min_samples=5).fit(coords_2)\n",
    "labels_2 = db.labels_\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "df_filter_2 = df_filter_2.assign(Classe_spaziale = labels_2)\n",
    "print(Counter(labels_2))\n",
    "\n",
    "#filtro la label di interesse\n",
    "df_cluster_2 = df_filter_2[df_filter_2['Classe_spaziale'] == 0]  # <========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imposto i dati "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importo il file depurato degli outlayer:\n",
    "#df = pd.read_csv('taggia_saorge_ripulita_outlier.csv', sep=',', names=['x', 'y','z'])\n",
    "\n",
    "x = df_cluster_2['x']  \n",
    "\n",
    "y = df_cluster_2['y']   \n",
    "\n",
    "z = df_cluster_2['z']\n",
    "\n",
    "W = df_cluster_2['weights']\n",
    "\n",
    "\n",
    "data_orig =  df_cluster_2[['x','y','z']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimi quadrati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.416\n",
      "Model:                            WLS   Adj. R-squared:                  0.388\n",
      "Method:                 Least Squares   F-statistic:                     15.29\n",
      "Date:                Fri, 24 Apr 2020   Prob (F-statistic):           9.65e-06\n",
      "Time:                        22:20:05   Log-Likelihood:                -424.58\n",
      "No. Observations:                  46   AIC:                             855.2\n",
      "Df Residuals:                      43   BIC:                             860.7\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.7266      0.211      3.437      0.001       0.300       1.153\n",
      "x2            -0.1476      0.188     -0.786      0.436      -0.526       0.231\n",
      "const      -3.935e+06   1.37e+06     -2.865      0.006    -6.7e+06   -1.17e+06\n",
      "==============================================================================\n",
      "Omnibus:                        0.623   Durbin-Watson:                   1.492\n",
      "Prob(Omnibus):                  0.732   Jarque-Bera (JB):                0.432\n",
      "Skew:                           0.235   Prob(JB):                        0.806\n",
      "Kurtosis:                       2.928   Cond. No.                     2.31e+10\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.31e+10. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "[[ 3.00304913e-01  1.15292816e+00]\n",
      " [-5.26073882e-01  2.30908779e-01]\n",
      " [-6.70483681e+06 -1.16558664e+06]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A_ = np.c_[data_orig[:,0], data_orig[:,1], np.ones(data_orig.shape[0])]\n",
    "L = data_orig[:,2]\n",
    "\n",
    "wls_model = sm.WLS(L,A_,W)\n",
    "wls_result = wls_model.fit()\n",
    "\n",
    "print(wls_result.summary())\n",
    "print(wls_result.conf_int())\n",
    "\n",
    "\n",
    "x1,x2,const= wls_result.params\n",
    "# x1_err, x2_err, const_err = wls_result.conf_int() prima versione prendeva in considerazione intervallo di confidenza\n",
    "x1_err, x2_err, const_err = wls_result.bse\n",
    "\n",
    "\n",
    "x1_err_max = x1 + x1_err\n",
    "x2_err_max = x2 + x2_err\n",
    "const_err_max = const + const_err\n",
    "\n",
    "\n",
    "x1_err_min = x1 - x1_err\n",
    "x2_err_min = x2 -  x2_err\n",
    "const_err_min = const - const_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.11391517e-01 1.87679276e-01 1.37335043e+06]\n"
     ]
    }
   ],
   "source": [
    "print(wls_result.bse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert an affine function (<class 'uncertainties.core.AffineScalarFunc'>) to float; use x.nominal_value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-9d227764c3c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mplot_dip_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_dip_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdip_direction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mplot_dip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_dip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dip_direction= %f ; dip= %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdip_direction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'##################################################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/Tesi/lib/python3.7/site-packages/uncertainties/core.py\u001b[0m in \u001b[0;36mraise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2668\u001b[0m                             \u001b[0;34m' to %s; use x.nominal_value'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m                             \u001b[0;31m# In case AffineScalarFunc is sub-classed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2670\u001b[0;31m                             % (self.__class__, coercion_type))\n\u001b[0m\u001b[1;32m   2671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAffineScalarFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__%s__'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcoercion_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert an affine function (<class 'uncertainties.core.AffineScalarFunc'>) to float; use x.nominal_value"
     ]
    }
   ],
   "source": [
    "A=x1\n",
    "B=x2\n",
    "D=const\n",
    "C_ = -1\n",
    "\n",
    "\n",
    "A = ufloat(A, 2.32031598e-01)  # x = 1+/-0.1\n",
    "B = ufloat(B, 2.45795013e-01)\n",
    "D = ufloat(D, 1.45839563e+06)\n",
    "C_= ufloat(C_, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #calcolo E\n",
    "E=umath.sqrt(A**2 + B**2 + 1)\n",
    "\n",
    "#calcolo i coseni\n",
    "cos_a = A/E\n",
    "\n",
    "cos_b = B/E\n",
    "\n",
    "cos_cp = C_/E  #gamma_p\n",
    "\n",
    "\n",
    "cos_c = unumpy.cos((math.pi/2) + unumpy.arccos(C_/E))   #controllare se è corretto \n",
    "\n",
    "#calcolo la direzione teta del vettore, il coseni direttori danno la direzione del vettore occorrre aggiungere 90°\n",
    "teta_primo = unumpy.arctan(cos_a/cos_b)   #espresso in radianti\n",
    "teta_deg = (teta_primo*180)/np.pi \n",
    "\n",
    "#calcolo della direzione della massima pendenza sul piano\n",
    "#dip_direction = teta_deg \n",
    "\n",
    "#calcolo l'immersione dip angolo tra la verticale e il piano\n",
    "dip_vert = unumpy.arcsin(-1*cos_c)\n",
    "dip_deg = (dip_vert*180)/np.pi\n",
    "\n",
    "#calcolo l'immersione dip\n",
    "dip = dip_deg\n",
    "#occorre orientare correttamente il dip_direction\n",
    "#cond_1 = dip_direction = teta_deg\n",
    "#cond_2 = dip_direction = teta_deg + 180\n",
    "#cond_3 = dip_direction =  teta_deg + 360\n",
    "\n",
    "#def orientation(cos_a,cos_b):\n",
    "\n",
    "if cos_a > 0 and cos_b > 0:                \n",
    "    dip_direction = teta_deg\n",
    "    if cos_cp <0:\n",
    "        dip_direction =  dip_direction + 180\n",
    "\n",
    "if  cos_a > 0 and cos_b < 0:\n",
    "    dip_direction = teta_deg + 180\n",
    "    if cos_cp <0:\n",
    "        dip_direction =  dip_direction + 180\n",
    "\n",
    "\n",
    "if  cos_a < 0 and cos_b < 0:\n",
    "    dip_direction = teta_deg + 180\n",
    "    if cos_cp <0:\n",
    "        dip_direction =  dip_direction - 180\n",
    "\n",
    "\n",
    "if  cos_a < 0 and cos_b > 0:\n",
    "    dip_direction =  teta_deg + 360\n",
    "    if cos_cp <0:\n",
    "        dip_direction =  dip_direction - 180\n",
    "\n",
    "#creo l'array per il plotaggio su stereogramma\n",
    "plot_dip_direction = 0\n",
    "plot_dip = 0\n",
    "plot_dip_direction = np.append(plot_dip_direction, dip_direction)\n",
    "plot_dip = np.append(plot_dip, dip)\n",
    "print(\"dip_direction= %f ; dip= %f\" % (dip_direction, dip))\n",
    "print(cos_a, cos_b)\n",
    "print('##################################################')\n",
    "print(teta_deg)\n",
    "output = \"teta= %f ; dip= %f\" % (dip_direction, dip)\n",
    "file = open(\"giacitura_cluster_xx_plane.txt\",\"w\")\n",
    "file.write(output)\n",
    "file.close()\n",
    "\n",
    "daframe_cluster_xx = pd.DataFrame.to_csv(df_cluster_2)\n",
    "file = open(\"daframe_cluster_xx_plane.csv\",\"w\")\n",
    "file.write(daframe_cluster_xx)\n",
    "file.close()\n",
    "\n",
    "#salva i risultati su di un file shape\n",
    "geometry = [Point(xy) for xy in zip(df_cluster_2.x , df_cluster_2.y)]\n",
    "df_shape = df_cluster_2.drop(['x', 'y','Ora', 'Data', 'Sec'], axis=1)\n",
    "crs = {'init': 'epsg:3003'}\n",
    "gdf = GeoDataFrame( df_shape, crs=crs, geometry=geometry)   #df_shape,\n",
    "gdf.to_file(driver = 'ESRI Shapefile', filename= \"result_xx_plane.shp\" )\n",
    "\n",
    "\n",
    "\n",
    "strike = plot_dip_direction - 90 \n",
    "dip =  plot_dip\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='stereonet')\n",
    "ax.plane(strike, dip)\n",
    "ax.pole(strike, dip ,markersize=5)\n",
    "ax.grid()\n",
    "plt.show() \n",
    "\n",
    "\n",
    "print(dip)\n",
    "print(dip_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=x1\n",
    "B=x2\n",
    "C_=-1\n",
    "D=const\n",
    "\n",
    "print(A,B,C_,D)\n",
    "piano(A,B,C_,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=x1\n",
    "B=x2\n",
    "C_=-1\n",
    "D=const\n",
    "\n",
    "\n",
    "piano(A,B,C_,D)\n",
    "print(A,B,C_,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=x1_err_max\n",
    "B=x2_err_max\n",
    "C_=-1\n",
    "D=const_err_max\n",
    "\n",
    "print(A,B,C_,D)\n",
    "piano(A,B,C_,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=x1_err_min\n",
    "B=x2_err_min\n",
    "C_=-1\n",
    "D=const_err_min\n",
    "\n",
    "print(A,B,C_,D)\n",
    "piano(A,B,C_,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definisco le Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = np.min(data_orig, axis=0)\n",
    "mx = np.max(data_orig, axis=0)\n",
    "X,Y = np.meshgrid(np.linspace(mn[0], mx[0], 20), np.linspace( mx[1],mn[1], 20))\n",
    "\n",
    "\n",
    "z_err_1 = x1_err_max*X + x2_err_max*Y + const_err_max\n",
    "z_err_2 = x1_err_min*X + x2_err_min*Y + const_err_min\n",
    "\n",
    "\n",
    "Z= wls_result.params[0]*X + wls_result.params[1]*Y + wls_result.params[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wls_result.params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_plane(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una matrice dei coefficenti del piano attraverso la combinazione dei dell'errore dei coeficienti\n",
    "import itertools\n",
    "coef_matrix_err = []\n",
    "for x in itertools.product([\"A+\", \"A-\"], [\"B+\",  \"B-\"],[\"C+\",\"C-\"]):\n",
    "    coef_matrix_err.append(x) \n",
    "print(coef_matrix_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una matrice dei coefficenti del piano attraverso la combinazione dei dell'errore dei coeficienti\n",
    "\n",
    "import itertools\n",
    "coef_matrix_err = []\n",
    "for x in itertools.product([x1_err_max, x1_err_min], [x2_err_max,  x2_err_min],[const_err_max,const_err_min]):\n",
    "    coef_matrix_err.append(x) \n",
    "print(coef_matrix_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ = globals()\n",
    "B_ = globals()\n",
    "D_ = globals()\n",
    "Z_ = globals()\n",
    "\n",
    "for x in range(0,8):\n",
    "    A_['A_%d' % x],B_['B_%d' % x],D_['D_%d' % x] = coef_matrix_err[x]\n",
    "    \n",
    "    Z_['Z_%d' % x] = A_['A_%d' % x]*X + B_['B_%d' % x]*Y + D_['D_%d' % x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_9_plane(Z,Z_0,Z_1,Z_2,Z_3,Z_4,Z_5,Z_6,Z_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
